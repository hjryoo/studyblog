---
title: "나노바나나(NanoBanana) 커스텀 학습: LoRA를 이용한 화풍 미세조정"
date: 2025-12-17 00:00:00 +0900
categories: [Training, Fine-tuning]
tags: [LoRA, Peft, NanoBanana, Custom Model, Python]
---

## 들어가는 글
**LoRA(Low-Rank Adaptation)** 기술을 활용하여 나노바나나 모델을 효율적으로 파인튜닝하는 방법을 다룬다. 1.5B라는 작은 파라미터 사이즈 덕분에, 나노바나나의 학습은 기존 SDXL 모델 대비 압도적으로 빠르고 가볍다.

## 학습 데이터셋 준비 (Dataset Preparation)

나노바나나 학습의 가장 큰 차별점은 **데이터 라벨링(Captioning)** 방식에 있다.

기존 모델들은 `1girl, blue hair, white background`와 같은 태그(Tag) 중심의 캡션을 선호했다. 하지만 LLM 인코더를 사용하는 나노바나나는 **자연어 설명**을 더 잘 이해한다.

### 데이터 구조 예시
학습용 이미지는 약 15~20장 정도면 스타일 학습에 충분하다.

```text
/dataset
  ├── image_01.jpg
  ├── image_01.txt
  ├── image_02.jpg
  ├── image_02.txt
  ...
```

### 캡션 작성 팁
`image_01.txt`의 내용은 다음과 같이 서술형으로 작성하는 것이 좋다.
> "A sketch style illustration of a cyberpunk robot sitting on a bench, drawn with rough pencil lines and minimal shading."

## 학습 환경 및 설정

학습은 추론보다 많은 VRAM을 요구한다. 하지만 나노바나나는 가볍기 때문에 **8GB VRAM** 환경에서도 배치 사이즈(Batch Size) 1로 학습이 가능하다. (12GB 이상 권장)

### 필수 라이브러리 설치
학습 스크립트는 `peft` 라이브러리에 의존한다.

```bash
pip install peft bitsandbytes
```

### 학습 스크립트 실행 (Training Script)

나노바나나 공식 리포지토리에서 제공하는 `train_banana_lora.py`를 사용한다고 가정한다. 주요 하이퍼파라미터 설정은 다음과 같다.

- **Rank (r):** 16 ~ 32 (작을수록 용량이 적고, 클수록 정교하지만 과적합 위험)
- **Learning Rate:** 1e-4 (UNet), 5e-5 (Text Encoder)
- **Mixed Precision:** fp16

```bash
accelerate launch train_banana_lora.py \
  --pretrained_model_name_or_path="banana-ai/nano-banana-v1-base" \
  --train_data_dir="./dataset/my_sketch_style" \
  --output_dir="./output/sketch-lora" \
  --resolution=1024 \
  --train_batch_size=1 \
  --gradient_accumulation_steps=4 \
  --learning_rate=1e-4 \
  --max_train_steps=1000 \
  --lora_rank=32 \
  --mixed_precision="fp16" \
  --use_8bit_adam  # 메모리 절약을 위한 8bit 옵티마이저
```

이 명령어를 실행하면, RTX 3060 기준으로 약 20분 내외에 학습이 완료된다. SDXL 학습이 몇 시간씩 걸리던 것에 비하면 혁신적인 속도다.

## 학습 결과물 로드 및 추론

학습이 완료되면 `output/sketch-lora` 폴더에 `.safetensors` 파일이 생성된다. 용량은 약 50MB~100MB 수준이다. 이를 베이스 모델에 로드하여 확인해보자.

```python
import torch
from nano_banana import BananaPipeline

model_id = "banana-ai/nano-banana-v1-base"
pipe = BananaPipeline.from_pretrained(model_id, torch_dtype=torch.float16)
pipe.to("cuda")

# LoRA 가중치 로드
# adapter_name을 지정하여 여러 LoRA를 섞어 쓸 수도 있다.
pipe.load_lora_weights("./output/sketch-lora", adapter_name="sketch")

prompt = "A futuristic car drifting on a highway"

# LoRA 스케일 조절 (0.0 ~ 1.0)
# 1.0이면 학습된 스타일을 100% 반영한다.
image = pipe(
    prompt=prompt,
    num_inference_steps=30,
    cross_attention_kwargs={"scale": 0.8} 
).images[0]

image.save("lora_result.png")
```

### 결과 분석 및 주의사항 (Overfitting)
생성된 이미지를 확인했을 때, 학습 데이터의 이미지가 그대로 나오거나 노이즈가 심하다면 **과적합(Overfitting)**된 것이다.

이 경우 다음 조치를 취해볼 수 있다.
1. `max_train_steps`를 줄인다. (예: 1000 -> 600)
2. `lora_rank`를 낮춘다. (예: 32 -> 8)
3. 추론 시 `scale` 값을 0.6~0.7 수준으로 낮춘다.

## 나노바나나 파인튜닝의 의의

나노바나나의 LoRA 학습은 단순히 스타일을 입히는 것을 넘어, **LLM 인코더의 해석 능력을 특정 도메인에 맞추는 효과**도 있다.

예를 들어, 의료 이미지를 학습시킬 때 "X-ray"라는 단어의 미세한 뉘앙스를 LLM 인코더가 학습 과정에서 함께 튜닝(Text Encoder Training 옵션 활성화 시)됨으로써, 훨씬 더 정확한 도메인 특화 이미지를 얻을 수 있다.